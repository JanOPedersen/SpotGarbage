{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "e6d389e96998f597cee0fc4b39534997436beb1ddafc62a05299fd5c50d2177c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "In this notebook we load, modify and train the AlexNet model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-06-28 16:06:07.459 | WARNING  | torch_snippets.torch_loader:<module>:233 - Not importing Lightning Report\n",
      "2021-06-28 16:06:08.833 | WARNING  | torch_snippets:<module>:13 - sklearn is not found. Skipping relevant imports from submodule `sklegos`\n",
      "Exception: No module named 'sklego'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1;36m1\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1;35m_CudaDeviceProperties\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'GeForce GTX 1050'\u001b[0m, \u001b[33mmajor\u001b[0m=\u001b[1;36m6\u001b[0m, \u001b[33mminor\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mtotal_memory\u001b[0m=\u001b[35m4096MB\u001b[0m, \n\u001b[33mmulti_processor_count\u001b[0m=\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_CudaDeviceProperties</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'GeForce GTX 1050'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">major</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #808000; text-decoration-color: #808000\">minor</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">total_memory</span>=<span style=\"color: #800080; text-decoration-color: #800080\">4096MB</span>, \n<span style=\"color: #808000; text-decoration-color: #808000\">multi_processor_count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import os\n",
    "from torch_snippets import *\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from pathlib import PurePath\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "from scipy.stats import shapiro\n",
    "import matplotlib\n",
    "from tqdm import tnrange,notebook\n",
    "import cv2 as cv2\n",
    "from glob import glob\n",
    "import math\n",
    "import torch \n",
    "from torch.utils.data import Sampler\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_capability())\n",
    "print(torch.cuda.get_device_properties(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])"
   ]
  },
  {
   "source": [
    "Our Dataset overload is now a bit more sophisticated as it now implements k-fold stratified cross validation. Use sklearn for this"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = None\n",
    "df_train = None\n",
    "class pathchData(Dataset):\n",
    "    def __init__(self, split, train_data, n_splits=5, aug=None):\n",
    "        global splits\n",
    "        global df_train\n",
    "        self.train_data  = train_data\n",
    "        self.split       = split\n",
    "        self.aug         = aug\n",
    "        if splits == None:\n",
    "            splitter = StratifiedKFold(n_splits, shuffle=True, random_state=0)\n",
    "            df_train = pd.read_csv('spotgarbage-GINI-master\\spotgarbage\\\\train.csv', delimiter=',')\n",
    "            splits = []\n",
    "            for train_idx, test_idx in splitter.split(df_train['name'], df_train['class']):\n",
    "                splits.append((train_idx, test_idx))\n",
    "            torch.save(splits, 'spotgarbage-GINI-master\\spotgarbage\\\\splits.pt')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(splits[self.split][0]) if self.train_data else len(splits[self.split][1])\n",
    "    def __getitem__(self, ix):\n",
    "        i = 0 if self.train_data else 1\n",
    "        #fullName = df_train['name'][splits[self.split][0][ix]] if self.train_data else df_train['name'][splits[self.split][1][ix]]\n",
    "        #garbageClass = df_train['class'][splits[self.split][0][ix]] if self.train_data else df_train['class'][splits[self.split][1][ix]]\n",
    "\n",
    "        fullName = df_train['name'][splits[self.split][i][ix]]\n",
    "        garbageClass = df_train['class'][splits[self.split][i][ix]]\n",
    "\n",
    "        image = read(f'spotgarbage-GINI-master/spotgarbage/patches/{fullName}',1)\n",
    "        image = cv2.resize(image, (227, 227))\n",
    "        return image, 1 if garbageClass == 'garbage' else 0\n",
    "    def choose(self): return self[randint(len(self))]\n",
    "    def collate_fn(self, batch):\n",
    "        ims, garbageClasses = list(zip(*batch))\n",
    "        ims = torch.cat([tfms(im.copy()/255.)[None] for im in ims]).float().to(device)\n",
    "        garbageClasses = torch.tensor(garbageClasses).to(device)\n",
    "        return ims, garbageClasses"
   ]
  },
  {
   "source": [
    "Now that we have created the datasets lets validate the content. First how much data in each training and validation set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_folds):\n",
    "    print(len(trn_ds[i]))\n",
    "    print(len(val_ds[i]))"
   ]
  },
  {
   "source": [
    "Second, do the indexed data look different in each fold"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_folds):\n",
    "    #print(trn_ds[i][9])\n",
    "    #print(val_ds[i][9])\n",
    "\n",
    "    #print(trn_ds[i][108000 - 1])\n",
    "    #print(val_ds[i][22000 - 1])"
   ]
  },
  {
   "source": [
    "Third, check out the number of garbage and non garbage classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ngarb = 0\n",
    "Nnongarb = 0\n",
    "for i in range(N_folds):\n",
    "    for j in range(208000):\n",
    "        if trn_ds[i][j][1] == 1:\n",
    "             Ngarb += 1\n",
    "\n",
    "        if trn_ds[i][j][1] == 0:\n",
    "             Nnongarb += 1\n",
    "\n",
    "    for j in range(52000):\n",
    "        if val_ds[i][j][1] == 1:\n",
    "             Ngarb += 1\n",
    "\n",
    "        if val_ds[i][j][1] == 0:\n",
    "             Nnongarb += 1\n",
    "\n",
    "print(Ngarb)\n",
    "print(Nnongarb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trn_ds[0][600][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using cache found in C:\\Users\\janop/.cache\\torch\\hub\\pytorch_vision_v0.9.0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
      "              ReLU-2           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                  [-1, 512]       4,719,104\n",
      "             ReLU-17                  [-1, 512]               0\n",
      "          Dropout-18                  [-1, 512]               0\n",
      "           Linear-19                  [-1, 256]         131,328\n",
      "             ReLU-20                  [-1, 256]               0\n",
      "           Linear-21                    [-1, 2]             514\n",
      "================================================================\n",
      "Total params: 7,320,642\n",
      "Trainable params: 4,850,946\n",
      "Non-trainable params: 2,469,696\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 8.34\n",
      "Params size (MB): 27.93\n",
      "Estimated Total Size (MB): 36.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "alexnet = torch.hub.load('pytorch/vision:v0.9.0', 'alexnet', pretrained=True).to(device)\n",
    "\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "alexnet.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 6 * 6, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 2),\n",
    "        ).to(device)\n",
    "\n",
    "summary(alexnet, (3,227,227));"
   ]
  },
  {
   "source": [
    "And now for the training loop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    im, garbClass = data\n",
    "    out  = model(im)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(out, garbClass)\n",
    "    acc = (torch.max(out,1)[1] == garbClass).float().mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_batch(model, data, criterion):\n",
    "    model.eval()\n",
    "    im, garbClass = data\n",
    "    out = model(im)\n",
    "    loss = criterion(out, garbClass)\n",
    "    acc = (torch.max(out,1)[1] == garbClass).float().mean()\n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(alexnet.parameters(), lr=1e-3, momentum=0.9, weight_decay=5*1e-5)\n",
    "#criterion =  nn.BCELoss()# binary cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_epochs = 12 # 12\n",
    "N_folds = 5 # 5\n",
    "trn_ds = [pathchData(x, True) for x in range(N_folds)]\n",
    "val_ds = [pathchData(x, False) for x in range(N_folds)]\n",
    "trn_dl = [DataLoader(x, batch_size=100, shuffle=True, collate_fn=x.collate_fn) for x in trn_ds]\n",
    "val_dl = [DataLoader(x, batch_size=100, shuffle=True, collate_fn=x.collate_fn) for x in val_ds]\n",
    "log = Report(n_epochs * N_folds)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.25)"
   ]
  },
  {
   "source": [
    "We have 260.000 patches and with a batch size of 100 this gives us 2.600 batch iterations for 1 epoch. Each epoch takes 1.700 secs to complete, so if we run 60 of them it would take 1.700 minutes = 28 hours to complete. We subdivide the 60 epochs into 5 folds of 12 epochs each."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EPOCH: 1.000\ttrn_loss: 0.311\ttrn_acc: 0.867\tval_loss: 0.215\tval_acc: 0.911\t(1656.53s - 97735.21s remaining)\n",
      "EPOCH: 2.000\ttrn_loss: 0.218\ttrn_acc: 0.910\tval_loss: 0.144\tval_acc: 0.946\t(3278.65s - 95080.75s remaining)\n",
      "EPOCH: 3.000\ttrn_loss: 0.173\ttrn_acc: 0.932\tval_loss: 0.121\tval_acc: 0.957\t(4863.11s - 92399.05s remaining)\n",
      "EPOCH: 4.000\ttrn_loss: 0.157\ttrn_acc: 0.939\tval_loss: 0.105\tval_acc: 0.963\t(6324.43s - 88541.98s remaining)\n",
      "EPOCH: 5.000\ttrn_loss: 0.148\ttrn_acc: 0.943\tval_loss: 0.105\tval_acc: 0.962\t(8881.34s - 97694.76s remaining)\n",
      "EPOCH: 5.634\ttrn_loss: 0.205\ttrn_acc: 0.910\t(10280.44s - 99199.82s remaining)"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d006539337cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtrain_epoch_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mbx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malexnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mtrain_epoch_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-0d222ddeccb9>\u001b[0m in \u001b[0;36mcollate_fn\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgarbageClasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtfms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mims\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mgarbageClasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgarbageClasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgarbageClasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-0d222ddeccb9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgarbageClasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtfms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mims\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mgarbageClasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgarbageClasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgarbageClasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold in range(N_folds):\n",
    "    for ex in range(n_epochs):\n",
    "        N = len(trn_dl[fold])\n",
    "        train_epoch_losses = []\n",
    "        for bx, data in enumerate(trn_dl[fold]):\n",
    "            loss, acc = train_batch(alexnet, data, optimizer, criterion)\n",
    "            train_epoch_losses.append(loss) \n",
    "            log.record(ex + (bx + 1)/N, trn_loss=loss, trn_acc=acc, end='\\r')\n",
    "            \n",
    "        N = len(val_dl[fold])\n",
    "        val_epoch_losses = []\n",
    "        for bx, data in enumerate(val_dl[fold]):\n",
    "            loss, acc = validate_batch(alexnet, data, criterion)\n",
    "            val_epoch_losses.append(loss) \n",
    "            log.record(ex + (bx + 1)/N, val_loss=loss, val_acc=acc, end='\\r')\n",
    "  \n",
    "        torch.save(alexnet, 'spotgarbage-GINI-master\\spotgarbage\\\\alexnet_' + str(fold) + '_' + str(ex) + '.pth')\n",
    "        torch.save(train_epoch_losses, 'spotgarbage-GINI-master\\spotgarbage\\\\train_epoch_losses_' + str(fold) + '_' + str(ex) + '.pt')\n",
    "        torch.save(val_epoch_losses, 'spotgarbage-GINI-master\\spotgarbage\\\\val_epoch_losses_' + str(fold) + '_' + str(ex) + '.pt')\n",
    "\n",
    "        scheduler.step()\n",
    "        log.report_avgs(ex+1)\n",
    "   \n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (int, int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-97f368df24fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (int, int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "torch.max(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, garbClass = next(iter(val_dl[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out  = alexnet(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ -3.3597,   3.4526],\n",
       "        [ -3.2485,   2.8520],\n",
       "        [  0.3248,  -0.2680],\n",
       "        [  2.7095,  -2.4543],\n",
       "        [ -2.8512,   2.6342],\n",
       "        [  4.7454,  -4.6222],\n",
       "        [ -5.2491,   5.0491],\n",
       "        [ -2.3398,   2.1222],\n",
       "        [  3.3411,  -3.2198],\n",
       "        [ -4.8146,   5.0951],\n",
       "        [ -1.9445,   2.0668],\n",
       "        [ -0.2203,   0.3922],\n",
       "        [ -1.6055,   1.4649],\n",
       "        [  1.0948,  -1.0070],\n",
       "        [  6.0334,  -5.6466],\n",
       "        [ -2.1474,   2.1200],\n",
       "        [  2.5957,  -2.3841],\n",
       "        [  4.3421,  -4.3331],\n",
       "        [ -1.8319,   1.7649],\n",
       "        [  1.6184,  -1.7473],\n",
       "        [ -1.7212,   1.5752],\n",
       "        [ -1.4695,   1.3732],\n",
       "        [ -0.7901,   0.5961],\n",
       "        [ -1.3765,   1.1080],\n",
       "        [ -5.0110,   4.6685],\n",
       "        [ -1.8524,   1.8293],\n",
       "        [ -1.1089,   1.0997],\n",
       "        [ -0.4512,   0.4505],\n",
       "        [ -4.0563,   4.0085],\n",
       "        [ -1.9422,   1.5386],\n",
       "        [  1.0727,  -1.1284],\n",
       "        [ -0.3423,   0.3862],\n",
       "        [ 12.2856, -12.3254],\n",
       "        [ -1.5669,   1.3280],\n",
       "        [ -1.7701,   1.3943],\n",
       "        [ -2.7135,   2.4063],\n",
       "        [  0.7023,  -0.5549],\n",
       "        [  4.4786,  -4.2165],\n",
       "        [ -2.1238,   1.9658],\n",
       "        [  5.3673,  -5.1280],\n",
       "        [  0.3716,  -0.5712],\n",
       "        [ -3.0539,   2.9919],\n",
       "        [  2.2898,  -2.3700],\n",
       "        [ -2.3227,   2.2599],\n",
       "        [ -0.5103,   0.2966],\n",
       "        [  2.8255,  -2.7273],\n",
       "        [  1.0197,  -0.8672],\n",
       "        [ -2.3515,   1.9151],\n",
       "        [ -3.0221,   2.8816],\n",
       "        [ -2.9180,   2.6603],\n",
       "        [ -2.9060,   2.5599],\n",
       "        [ -0.6567,   0.2379],\n",
       "        [  4.7103,  -4.4787],\n",
       "        [  3.9452,  -4.1395],\n",
       "        [  3.9534,  -4.2335],\n",
       "        [ -2.1253,   2.0555],\n",
       "        [  3.7394,  -3.2401],\n",
       "        [  1.2321,  -1.2442],\n",
       "        [  1.4673,  -1.4571],\n",
       "        [ -2.4760,   2.2293],\n",
       "        [  6.5259,  -6.1896],\n",
       "        [ -1.6579,   1.8104],\n",
       "        [ -2.6184,   2.2221],\n",
       "        [ -0.7273,   0.5999],\n",
       "        [  0.4273,  -0.4222],\n",
       "        [ -2.2873,   1.9722],\n",
       "        [ 12.6674, -11.8544],\n",
       "        [  5.3509,  -5.0879],\n",
       "        [  0.5017,  -0.8123],\n",
       "        [ -3.6017,   3.6658],\n",
       "        [  2.5241,  -2.6784],\n",
       "        [  2.3603,  -2.3488],\n",
       "        [ -1.1762,   1.2751],\n",
       "        [  4.1808,  -4.1047],\n",
       "        [ -0.8435,   0.7436],\n",
       "        [ -0.8330,   0.7468],\n",
       "        [ -1.1799,   1.0394],\n",
       "        [ -2.3348,   2.2641],\n",
       "        [ -3.6748,   3.5449],\n",
       "        [  6.4017,  -6.3275],\n",
       "        [ -1.6702,   1.3355],\n",
       "        [ -3.1202,   2.9460],\n",
       "        [  0.4760,  -0.8136],\n",
       "        [ -0.9204,   1.1803],\n",
       "        [  4.5968,  -4.5271],\n",
       "        [ -1.6173,   1.4386],\n",
       "        [  3.5434,  -3.4034],\n",
       "        [ -0.9904,   0.9716],\n",
       "        [ -1.9178,   2.1668],\n",
       "        [ -0.3786,   0.2228],\n",
       "        [ -1.8899,   1.8259],\n",
       "        [  6.3194,  -6.4774],\n",
       "        [  6.3600,  -5.9061],\n",
       "        [ -3.4561,   3.3500],\n",
       "        [ -0.2657,   0.1376],\n",
       "        [  2.0991,  -2.1933],\n",
       "        [  4.0349,  -3.8590],\n",
       "        [ -0.6774,   0.8460],\n",
       "        [ -2.6503,   2.7086],\n",
       "        [ -1.0933,   0.9590]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (torch.max(out,1)[1] == garbClass).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.9600, device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "torch.max(out,1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([ 3.4526,  2.8520,  0.3248,  2.7095,  2.6342,  4.7454,  5.0491,  2.1222,\n",
       "         3.3411,  5.0951,  2.0668,  0.3922,  1.4649,  1.0948,  6.0334,  2.1200,\n",
       "         2.5957,  4.3421,  1.7649,  1.6184,  1.5752,  1.3732,  0.5961,  1.1080,\n",
       "         4.6685,  1.8293,  1.0997,  0.4505,  4.0085,  1.5386,  1.0727,  0.3862,\n",
       "        12.2856,  1.3280,  1.3943,  2.4063,  0.7023,  4.4786,  1.9658,  5.3673,\n",
       "         0.3716,  2.9919,  2.2898,  2.2599,  0.2966,  2.8255,  1.0197,  1.9151,\n",
       "         2.8816,  2.6603,  2.5599,  0.2379,  4.7103,  3.9452,  3.9534,  2.0555,\n",
       "         3.7394,  1.2321,  1.4673,  2.2293,  6.5259,  1.8104,  2.2221,  0.5999,\n",
       "         0.4273,  1.9722, 12.6674,  5.3509,  0.5017,  3.6658,  2.5241,  2.3603,\n",
       "         1.2751,  4.1808,  0.7436,  0.7468,  1.0394,  2.2641,  3.5449,  6.4017,\n",
       "         1.3355,  2.9460,  0.4760,  1.1803,  4.5968,  1.4386,  3.5434,  0.9716,\n",
       "         2.1668,  0.2228,  1.8259,  6.3194,  6.3600,  3.3500,  0.1376,  2.0991,\n",
       "         4.0349,  0.8460,  2.7086,  0.9590], device='cuda:0',\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 1], device='cuda:0'))"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "torch.max(out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}